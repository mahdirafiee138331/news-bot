# -*- coding: utf-8 -*-
import os
import logging
import json
import re
import requests
import time
import feedparser
import google.generativeai as genai
from urllib.parse import quote
import schedule
import html as html_lib

# --- Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­Ø±Ù…Ø§Ù†Ù‡ ---
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
ADMIN_CHAT_ID = os.environ.get("ADMIN_CHAT_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
ADMIN_NAME = os.environ.get("ADMIN_NAME", "Ø¬Ù†Ø§Ø¨ Ø±ÙÛŒØ¹ÛŒ")

# --- Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¬Ù…ÛŒÙ†Ø§ÛŒ ---
try:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-pro')
except Exception as e:
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¬Ù…ÛŒÙ†Ø§ÛŒ: {e}")
    model = None

# --- Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ (Ø¯Ø± Railway Ù…ÙˆÙ‚ØªÛŒ Ù‡Ø³ØªÙ†Ø¯) ---
DB_FILE = os.environ.get("DB_FILE", "/tmp/bot_database.json")
URL_FILE = os.environ.get("URL_FILE", "urls.txt")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

KEYWORD_CATEGORIES = {
    "ğŸ”µ": ['Ù†Ø¬ÙˆÙ…', 'ÙÛŒØ²ÛŒÚ©', 'Ú©ÛŒÙ‡Ø§Ù†', 'Ú©ÙˆØ§Ù†ØªÙˆÙ…', 'Ø³ØªØ§Ø±Ù‡', 'Ú©Ù‡Ú©Ø´Ø§Ù†', 'Ø³ÛŒØ§Ù‡Ú†Ø§Ù„Ù‡', 'Ø§Ø®ØªØ±Ø´Ù†Ø§Ø³ÛŒ', 'Ø³ÛŒØ§Ø±Ù‡', 'physics', 'astronomy', 'cosmos', 'galaxy', 'planet'],
    "ğŸŸ¡": ['Ø²ÛŒØ³Øª', 'Ú˜Ù†ØªÛŒÚ©', 'ÙØ±Ú¯Ø´Øª', 'dna', 'Ø³Ù„ÙˆÙ„', 'Ù…ÙˆÙ„Ú©ÙˆÙ„', 'Ø¨ÛŒÙˆÙ„ÙˆÚ˜ÛŒ', 'ØªÚ©Ø§Ù…Ù„', 'biology', 'evolution', 'genetic'],
    "âš«": ['Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ', 'ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†', 'Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ', 'Ø±Ø¨Ø§ØªÛŒÚ©', 'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…', 'Ø¯ÛŒÙ¾ Ù„Ø±Ù†ÛŒÙ†Ú¯', 'ai', 'artificial intelligence', 'machine learning'],
    "ğŸ”´": ['Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ', 'Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ÛŒ', 'Ø¹Ù„ÙˆÙ… Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ', 'Ø±ÙØªØ§Ø±', 'Ø°Ù‡Ù†', 'Ø±ÙˆØ§Ù†', 'Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ', 'psychology', 'sociology', 'social'],
    "ğŸŸ ": ['ÙÙ„Ø³ÙÙ‡', 'ÙÙ„Ø³ÙÙ‡ Ø¹Ù„Ù…', 'Ù…Ù†Ø·Ù‚', 'Ù…ØªØ§ÙÛŒØ²ÛŒÚ©', 'Ø§Ø®Ù„Ø§Ù‚', 'philosophy']
}


def load_data():
    try:
        with open(DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {"last_sent_links": {}}
    except json.JSONDecodeError:
        logging.warning("ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø®Ø±Ø§Ø¨ Ø§Ø³Øª â€” Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø¬Ø¯Ø¯ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return {"last_sent_links": {}}


def save_data(data):
    try:
        with open(DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")


def clean_html(raw_html):
    if not raw_html:
        return ""
    # Ø­Ø°Ù ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML Ø¨Ù‡ ØµÙˆØ±Øª non-greedy
    return re.sub(re.compile('<.*?>'), '', raw_html)


def categorize_article(text):
    text_lower = (text or "").lower()
    emojis = ""
    for emoji, keywords in KEYWORD_CATEGORIES.items():
        if any(keyword in text_lower for keyword in keywords):
            emojis += emoji
    return emojis if emojis else "ğŸ“°"


def send_telegram_message(text):
    if not TELEGRAM_BOT_TOKEN or not ADMIN_CHAT_ID:
        logging.error("ØªÙˆÚ©Ù† ØªÙ„Ú¯Ø±Ø§Ù… ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ø§Ø¯Ù…ÛŒÙ† ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return False

    send_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HTML mode Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ø´Ø¯Ù† escape
    payload = {
        "chat_id": ADMIN_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    try:
        r = requests.post(send_url, json=payload, timeout=15)
        r.raise_for_status()
        return True
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {e} - response: {getattr(e, 'response', None)}")
        return False


def process_with_gemini(title, summary):
    # Ø§Ú¯Ø± Ù…Ø¯Ù„ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ØŒ fallback
    if model is None:
        logging.warning("Ù…Ø¯Ù„ Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ù†Ø´Ø¯Ù‡Ø› Ø®Ø±ÙˆØ¬ÛŒ fallback Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
        return f"{html_lib.escape(title)}\n\n(Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª)"

    try:
        prompt = (
            "You are an expert science communicator. Your task is to perform two steps based on the following English text:\n"
            "1. Provide a fluent and professional Persian translation of ONLY the title.\n"
            "2. After the title, explain the core concept of the article in a few simple and conceptual Persian sentences, as if you are explaining it to an expert student (like Ø´Ø§Ú¯Ø±Ø¯Ù… in Persian).\n\n"
            f"Title: '{title}'\n"
            f"Summary: '{summary}'\n\n"
            "Your final output must be in Persian and structured exactly like this:\n"
            "[Persian Title]\n\n"
            "[Simple and conceptual Persian explanation]"
        )
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ø¬ÛŒâ€ŒÙ¾ÛŒâ€ŒØªÛŒ/Ø¬Ù…ÛŒÙ†Ø§ÛŒ
        response = model.generate_content(prompt)
        # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ response.text Ø­Ø§ÙˆÛŒ Ù…ØªÙ† Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª
        return response.text
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø¬Ù…ÛŒÙ†Ø§ÛŒ: {e}")
        return f"{html_lib.escape(title)}\n\n(Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯)"


def check_news_job():
    database = load_data()
    last_sent_links = database.get("last_sent_links", {})

    logging.info("Ø´Ø±ÙˆØ¹ ÛŒÚ© Ú†Ø±Ø®Ù‡ Ø¨Ø±Ø±Ø³ÛŒ ÙÛŒØ¯Ù‡Ø§...")
    try:
        with open(URL_FILE, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        logging.warning("ÙØ§ÛŒÙ„ urls.txt Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯! ÛŒÚ© ÙØ§ÛŒÙ„ urls.txt Ø¯Ø± Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨ Ø®ÙˆØ¯ Ø¨Ø³Ø§Ø²ÛŒØ¯ Ùˆ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ø¢Ù† Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")
        urls = []
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ URLs: {e}")
        urls = []

    # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ù„ÛŒØ³Øª URL
    seen = set()
    filtered_urls = []
    for u in urls:
        if u in seen:
            continue
        seen.add(u)
        filtered_urls.append(u)

    for url in filtered_urls:
        logging.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§ÛŒØª: {url}")
        try:
            # ØªÙ†Ø¸ÛŒÙ… Ù‡Ø¯Ø± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù†
            headers = {"User-Agent": "Telegram-RSS-Bot/1.0 (+https://example.org)"}
            # Ø§Ø² feedparser Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            feed = feedparser.parse(url)
            if not feed or not getattr(feed, "entries", None):
                logging.warning(f"ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØª {url} Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
                continue

            # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† 15 ÙˆØ±ÙˆØ¯ÛŒ (Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡ Ù‚Ø¯ÛŒÙ…)
            for entry in reversed(feed.entries[:15]):
                entry_id = getattr(entry, "id", None) or getattr(entry, "guid", None) or getattr(entry, "link", None)
                entry_link = getattr(entry, "link", None)
                if not entry_id:
                    logging.debug("ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø¯ÙˆÙ† id/link ÛŒØ§ÙØª Ø´Ø¯ â€” Ø§Ø² Ø¢Ù† Ø¹Ø¨ÙˆØ± Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….")
                    continue

                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ Ø§Ø³Øª
                already_sent = last_sent_links.get(url)
                if already_sent == entry_id:
                    # Ø§Ú¯Ø± Ù‡Ù…Ø§Ù† Ù„ÛŒÙ†Ú© Ø¢Ø®Ø± Ø§Ø³ØªØŒ Ø¨Ù‚ÛŒÙ‡ Ø±Ø§ Ù‡Ù… Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (Ù…Ù…Ú©Ù†Ù‡ Ù…ÙˆØ§Ø±Ø¯ Ø¬Ø¯ÛŒØ¯ØªØ± Ù‚Ø¨Ù„ Ø§Ø² Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯)
                    continue

                title = getattr(entry, "title", "(Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†)")
                summary_raw = getattr(entry, "summary", "") or getattr(entry, "description", "")
                summary = clean_html(summary_raw)
                full_content_for_cat = f"Title: {title}. Summary: {summary}"
                emojis = categorize_article(full_content_for_cat)

                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ø¬Ù…ÛŒÙ†Ø§ (ØªØ±Ø¬Ù…Ù‡ Ø¹Ù†ÙˆØ§Ù† + ØªÙˆØ¶ÛŒØ­ Ù…ÙÙ‡ÙˆÙ…ÛŒ)
                gemini_output = process_with_gemini(title, summary)

                # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ HTML-escaping
                # gemini_output Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´Ø§Ù…Ù„ Ú†Ù†Ø¯ Ø®Ø· Ø¨Ø§Ø´Ø¯Ø› Ù‡Ø±Ú†Ù‡ Ù‡Ø³Øª ÙØ±Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                escaped_output = html_lib.escape(gemini_output).replace("\n", "<br>")
                message_part = f"{emojis} <b>{escaped_output}</b>\n\n"
                if entry_link:
                    message_part += f"ğŸ”— <a href=\"{html_lib.escape(entry_link)}\">Ù„ÛŒÙ†Ú© Ù…Ù‚Ø§Ù„Ù‡ Ø§ØµÙ„ÛŒ</a>"

                sent = send_telegram_message(message_part)
                if sent:
                    # Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª: Ø¨Ø±Ø§ÛŒ Ù‡Ø± URL Ø¢Ø®Ø±ÛŒÙ† entry_id Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
                    last_sent_links[url] = entry_id
                    database["last_sent_links"] = last_sent_links
                    save_data(database)
                    logging.info(f"Ù…Ù‚Ø§Ù„Ù‡ Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {title}")
                    # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³Ù¾Ù… Ùˆ Ø±ÛŒØª Ù„ÛŒÙ…ÛŒØª ØªÙ„Ú¯Ø±Ø§Ù…
                    time.sleep(4)
                else:
                    logging.error(f"Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ {entry_link} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")

        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙÛŒØ¯ {url}: {e}")
            continue

    logging.info("Ù¾Ø§ÛŒØ§Ù† ÛŒÚ© Ú†Ø±Ø®Ù‡ Ø¨Ø±Ø±Ø³ÛŒ.")


if __name__ == "__main__":
    logging.info("Ø±Ø¨Ø§Øª Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ...")

    # Ø§Ú¯Ø± Ø¯Ø± Ù…Ø­ÛŒØ· GitHub Actions Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÛŒØ§ Ù…ØªØºÛŒØ± RUN_ONCE=1 ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù‡ØŒ
    # ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± Ú†Ú© Ú©Ù† Ùˆ Ø®Ø§Ø±Ø¬ Ø´Ùˆ (Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ workflow Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†Ø¨Ù†Ø¯ÛŒâ€ŒØ´Ø¯Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª)
    if os.environ.get("GITHUB_ACTIONS") == "true" or os.environ.get("RUN_ONCE") == "1":
        check_news_job()
    else:
        # Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø­Ù„ÛŒ Ø¯Ø§Ø¦Ù…ÛŒ Ø¨Ø§ schedule (Ù‡Ø± 6 Ø³Ø§Ø¹Øª)
        check_news_job()  # Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        schedule.every(6).hours.do(check_news_job)
        while True:
            schedule.run_pending()
            time.sleep(1)
