# -*- coding: utf-8 -*-
import os
import logging
import json
import re
import requests
import time
import feedparser
import html as html_lib
from time import mktime
from datetime import datetime, timezone, timedelta

# --- Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ) ---
try:
    from google import genai
except ImportError:
    genai = None
try:
    from openai import OpenAI as OpenAIClient
except ImportError:
    OpenAIClient = None

# --- Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­Ø±Ù…Ø§Ù†Ù‡ ---
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
ADMIN_CHAT_ID = os.environ.get("ADMIN_CHAT_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
GEMINI_MODEL_ENV = os.environ.get("GEMINI_MODEL")
OPENAI_MODEL_ENV = os.environ.get("OPENAI_MODEL", "gpt-3.5-turbo")

# --- Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---
DB_FILE = "bot_database.json"
URL_FILE = "urls.txt"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ
KEYWORD_CATEGORIES = {
    "ğŸ”µ": ['Ù†Ø¬ÙˆÙ…', 'ÙÛŒØ²ÛŒÚ©', 'Ú©ÛŒÙ‡Ø§Ù†', 'Ú©ÙˆØ§Ù†ØªÙˆÙ…', 'Ø³ØªØ§Ø±Ù‡', 'Ú©Ù‡Ú©Ø´Ø§Ù†', 'Ø³ÛŒØ§Ù‡Ú†Ø§Ù„Ù‡', 'Ø§Ø®ØªØ±Ø´Ù†Ø§Ø³ÛŒ', 'Ø³ÛŒØ§Ø±Ù‡', 'physics', 'astronomy', 'cosmos', 'galaxy', 'planet'],
    "ğŸŸ¡": ['Ø²ÛŒØ³Øª', 'Ú˜Ù†ØªÛŒÚ©', 'ÙØ±Ú¯Ø´Øª', 'dna', 'Ø³Ù„ÙˆÙ„', 'Ù…ÙˆÙ„Ú©ÙˆÙ„', 'Ø¨ÛŒÙˆÙ„ÙˆÚ˜ÛŒ', 'ØªÚ©Ø§Ù…Ù„', 'biology', 'evolution', 'genetic'],
    "âš«": ['Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ', 'ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†', 'Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ', 'Ø±Ø¨Ø§ØªÛŒÚ©', 'Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…', 'Ø¯ÛŒÙ¾ Ù„Ø±Ù†ÛŒÙ†Ú¯', 'ai', 'artificial intelligence', 'machine learning'],
    "ğŸ”´": ['Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ', 'Ø¬Ø§Ù…Ø¹Ù‡ Ø´Ù†Ø§Ø³ÛŒ', 'Ø¹Ù„ÙˆÙ… Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ', 'Ø±ÙØªØ§Ø±', 'Ø°Ù‡Ù†', 'Ø±ÙˆØ§Ù†', 'Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ', 'psychology', 'sociology', 'social'],
    "ğŸŸ ": ['ÙÙ„Ø³ÙÙ‡', 'ÙÙ„Ø³ÙÙ‡ Ø¹Ù„Ù…', 'Ù…Ù†Ø·Ù‚', 'Ù…ØªØ§ÙÛŒØ²ÛŒÚ©', 'Ø§Ø®Ù„Ø§Ù‚', 'philosophy']
}

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
MAX_AGE_DAYS = 2
MAX_AGE_SECONDS = MAX_AGE_DAYS * 24 * 60 * 60
DEFAULT_GEMINI_MODELS = ["gemini-1.5-flash", "gemini-1.5-pro"]

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
def load_data():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return {"last_sent_links": {}}
    return {"last_sent_links": {}}

def save_data(data):
    try:
        with open(DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")

def clean_html(raw_html):
    return re.sub(re.compile('<.*?>'), '', raw_html or "")

def categorize_article(text):
    text_lower = (text or "").lower()
    emojis = ""
    for emoji, keywords in KEYWORD_CATEGORIES.items():
        if any(keyword in text_lower for keyword in keywords):
            emojis += emoji
    return emojis if emojis else "ğŸ“°"

def entry_age_seconds(entry):
    t = entry.get("published_parsed") or entry.get("updated_parsed")
    if t:
        entry_ts = mktime(t)
        now_ts = time.time()
        return now_ts - entry_ts
    return -1 # -Û± ÛŒØ¹Ù†ÛŒ ØªØ§Ø±ÛŒØ® Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª

# --- ØªÙˆØ§Ø¨Ø¹ Ø§Ø±Ø³Ø§Ù„ Ùˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ---
def send_telegram_message(text):
    if not TELEGRAM_BOT_TOKEN or not ADMIN_CHAT_ID:
        logging.error("ØªÙˆÚ©Ù† ØªÙ„Ú¯Ø±Ø§Ù… ÛŒØ§ Ø´Ù†Ø§Ø³Ù‡ Ø§Ø¯Ù…ÛŒÙ† ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        return False
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {"chat_id": ADMIN_CHAT_ID, "text": text, "parse_mode": "HTML"}
    try:
        r = requests.post(url, json=payload, timeout=20)
        logging.info("Telegram response: %s", r.text)
        r.raise_for_status()
        return True
    except requests.exceptions.HTTPError as e:
        if "can't parse entities" in e.response.text:
            logging.warning("Ø®Ø·Ø§ÛŒ Parse_modeØŒ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ØªÙ† Ø³Ø§Ø¯Ù‡...")
            payload.pop('parse_mode', None)
            try:
                r = requests.post(url, json=payload, timeout=20)
                r.raise_for_status()
                return True
            except Exception as inner_e:
                logging.error(f"Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ù‡Ù… Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {inner_e}")
        return False
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {e}")
        return False

def openai_fallback(title, summary):
    if not OpenAIClient or not OPENAI_API_KEY:
        return None
    try:
        client = OpenAIClient(api_key=OPENAI_API_KEY)
        system_prompt = "You are a Persian science communicator. First, translate the user's article title to Persian. Then, on a new line, provide a simple, conceptual explanation of the article in 2-4 Persian sentences."
        user_content = f"Title: {title}\nSummary: {summary}"
        response = client.chat.completions.create(
            model=OPENAI_MODEL_ENV,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]
        )
        return response.choices[0].message.content
    except Exception as e:
        logging.error(f"ÙØ§Ù„â€ŒØ¨Ú© OpenAI Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")
        return None

def process_with_gemini(title, summary):
    if not genai or not GEMINI_API_KEY:
        logging.warning("Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ ÛŒØ§ Ú©Ù„ÛŒØ¯ Gemini Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ÙØ§Ù„â€ŒØ¨Ú©...")
        return openai_fallback(title, summary)
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        prompt = "You are an expert science communicator. Perform two steps based on the English text:\n1) Provide a fluent and professional Persian translation of ONLY the title.\n2) After the title, explain the core concept of the article in a few simple and conceptual Persian sentences.\n\nTitle: '{title}'\nSummary: '{summary}'\n\nOutput exactly in Persian. Structure:\n[Persian Title]\n\n[Persian explanation]".format(title=title, summary=summary)
        models_to_try = [GEMINI_MODEL_ENV] if GEMINI_MODEL_ENV else DEFAULT_GEMINI_MODELS
        for model_name in models_to_try:
            try:
                model = client.get_model(f"models/{model_name}")
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                logging.warning(f"Ù…Ø¯Ù„ {model_name} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")
        raise RuntimeError("ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù†Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø¬Ù…ÛŒÙ†Ø§ÛŒ: {e}. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ÙØ§Ù„â€ŒØ¨Ú© Ø¨Ø§ OpenAI...")
        return openai_fallback(title, summary)

# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª ---
def check_news_job():
    database = load_data()
    last_sent_links = database.get("last_sent_links", {})
    logging.info("Ø´Ø±ÙˆØ¹ Ú†Ø±Ø®Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø®Ø¨Ø§Ø±...")
    try:
        with open(URL_FILE, 'r', encoding='utf-8') as f:
            urls = {line.strip() for line in f if line.strip() and not line.startswith('#')}
    except FileNotFoundError:
        logging.warning("ÙØ§ÛŒÙ„ urls.txt Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
        urls = []

    for url in urls:
        logging.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§ÛŒØª: {url}")
        try:
            feed = feedparser.parse(url)
            if not feed or not feed.entries:
                logging.warning(f"ÙÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØª {url} Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")
                continue

            last_sent_id_for_url = last_sent_links.get(url)
            new_articles_to_send = []
            
            for entry in feed.entries:
                entry_id = entry.get('id', entry.link)
                if not entry_id: continue
                if entry_id == last_sent_id_for_url:
                    break
                new_articles_to_send.append(entry)

            for entry in reversed(new_articles_to_send):
                age_sec = entry_age_seconds(entry)
                if age_sec != -1 and age_sec > MAX_AGE_SECONDS:
                    logging.info(f"Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø§Ù„Ù‡ Ù‚Ø¯ÛŒÙ…ÛŒ: {entry.get('title')}")
                    continue

                title = entry.get("title", "(Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†)")
                summary = clean_html(entry.get("summary", "") or entry.get("description", ""))
                
                ai_output = process_with_gemini(title, summary)
                if not ai_output:
                    ai_output = f"<b>{html_lib.escape(title)}</b>\n\n(Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯)"

                emojis = categorize_article(f"Title: {title}. Summary: {summary}")
                message_part = f"{emojis} {ai_output}\n\nğŸ”— <a href='{html_lib.escape(entry.link)}'>Ù„ÛŒÙ†Ú© Ù…Ù‚Ø§Ù„Ù‡ Ø§ØµÙ„ÛŒ</a>"

                if send_telegram_message(message_part):
                    last_sent_links[url] = entry.get('id', entry.link)
                    logging.info(f"Ù…Ù‚Ø§Ù„Ù‡ Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {title}")
                    time.sleep(5)
                else:
                    logging.error(f"Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ù„Ù‡ {title} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
                    break
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙÛŒØ¯ {url}: {e}")
            continue
    
    save_data({"last_sent_links": last_sent_links})
    logging.info("Ù¾Ø§ÛŒØ§Ù† ÛŒÚ© Ú†Ø±Ø®Ù‡ Ø¨Ø±Ø±Ø³ÛŒ.")

if __name__ == "__main__":
    check_news_job()
